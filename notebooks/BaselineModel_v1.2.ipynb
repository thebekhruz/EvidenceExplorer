{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load pandas and numpy\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# For text preprocessing\n",
    "import spacy\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "# For text vectorization we will use Doc2Vec\n",
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
    "\n",
    "# For the classifier we will use Logistic Regression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# For evaluation we will use accuracy, f1-score, precesion, recall and confusion matrix\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, confusion_matrix\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Claim</th>\n",
       "      <th>Evidence</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>We should legalize the growing of coca leaf</td>\n",
       "      <td>Robert W. Sweet, a federal judge, strongly agr...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>We should ban trans fats usage in food</td>\n",
       "      <td>The net increase in LDL/HDL ratio with trans f...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>We should legalize prostitution</td>\n",
       "      <td>Pertaining to health, safety and services, the...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>We should subsidize investigative journalism</td>\n",
       "      <td>Date granted: 10 June 2002 Citation: \"For serv...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>We should abolish homework</td>\n",
       "      <td>The Yarrabah community has a public library wh...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          Claim  \\\n",
       "0   We should legalize the growing of coca leaf   \n",
       "1        We should ban trans fats usage in food   \n",
       "2               We should legalize prostitution   \n",
       "3  We should subsidize investigative journalism   \n",
       "4                    We should abolish homework   \n",
       "\n",
       "                                            Evidence  label  \n",
       "0  Robert W. Sweet, a federal judge, strongly agr...      1  \n",
       "1  The net increase in LDL/HDL ratio with trans f...      1  \n",
       "2  Pertaining to health, safety and services, the...      0  \n",
       "3  Date granted: 10 June 2002 Citation: \"For serv...      0  \n",
       "4  The Yarrabah community has a public library wh...      0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the datasets for training and testing\n",
    "filepath_train = '/Users/thebekhruz/Desktop/nlu/EvidenceExplorer/data/train/train.csv'\n",
    "filepath_test = '/Users/thebekhruz/Desktop/nlu/EvidenceExplorer/data/validate/dev.csv'\n",
    "\n",
    "df_train = pd.read_csv(filepath_train)\n",
    "df_test = pd.read_csv(filepath_test)\n",
    "\n",
    "# Check the first 5 rows of the training dataset\n",
    "df_train.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[TaggedDocument(words=['legalize', 'grow', 'coca', 'leaf', 'robert', 'w.', 'sweet', 'federal', 'judge', 'strongly', 'agree', 'present', 'policy', 'try', 'prohibit', 'use', 'drug', 'use', 'criminal', 'law', 'mistake', 'ref'], tags=['0']),\n",
       " TaggedDocument(words=['ban', 'trans', 'fat', 'usage', 'food', 'net', 'increase', 'ldl', 'hdl', 'ratio', 'trans', 'fat', 'approximately', 'double', 'saturate', 'fat', 'ref'], tags=['1']),\n",
       " TaggedDocument(words=['legalize', 'prostitution', 'pertain', 'health', 'safety', 'service', 'report', 'state', 'program', 'include', 'occupational', 'educational', 'program', 'health', 'program', 'continue', 'work', 'prostitute', 'wish', 'transition', 'occupation', 'ref'], tags=['2']),\n",
       " TaggedDocument(words=['subsidize', 'investigative', 'journalism', 'date', 'grant', '10', 'june', '2002', 'citation', 'service', 'community', 'investigative', 'journalism', 'western', 'australia', '\"[ref'], tags=['3']),\n",
       " TaggedDocument(words=['abolish', 'homework', 'yarrabah', 'community', 'public', 'library', 'serve', 'number', 'purpose', 'include', 'access', 'computer', 'internet', 'equipment', 'watch', 'movie', 'dvd', 'educational', 'link', 'include', 'homework', 'centre', 'federal', 'government', 'initiative', 'access', 'ratep', 'aboriginal', 'teacher', 'education', 'program', 'james', 'cook', 'university', 'townsville', 'training', 'teacher'], tags=['4'])]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Function to create tagged documents\n",
    "# This is required for Doc2Vec to train the model\n",
    "\n",
    "# We will use spaCy to tokenize and preprocess the text and then create tagged documents\n",
    "# Each document is tagged with the index of the row in the dataframe\n",
    "\n",
    "\n",
    "def create_tagged_document(df):\n",
    "    tagged_data = []\n",
    "    for i, text in enumerate(df['Claim'] + ' ' + df['Evidence']):\n",
    "        # Process the text with the spaCy language model\n",
    "        doc = nlp(text)\n",
    "        # Tokenize and lemmatize the text, removing stopwords\n",
    "        tokens = [token.lemma_.lower() for token in doc if not token.is_stop and not token.is_punct]\n",
    "        # Create a TaggedDocument for each row in the dataframe\n",
    "        tagged_data.append(TaggedDocument(words=tokens, tags=[str(i)]))  # Tags are typically strings\n",
    "    return tagged_data\n",
    "\n",
    "\n",
    "tagged_data_train = create_tagged_document(df_train)\n",
    "tagged_data_train[:5]\n",
    "\n",
    "# Takes around 3 min\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Doc2Vec Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finding the optimal parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate a Doc2Vec model\n",
    "# We will use a simple model with a vector size of 100 and a window size of 2\n",
    "# We will train the model for 20 epochs\n",
    "\n",
    "def train_doc2vec_model(tagged_data, vector_size=768, window=2, min_count=1, epochs=20, workers=4):\n",
    "    model = Doc2Vec(vector_size=vector_size, window=window, min_count=min_count, workers=workers, epochs=epochs)\n",
    "    model.build_vocab(tagged_data)\n",
    "    model.train(tagged_data, total_examples=model.corpus_count, epochs=epochs)\n",
    "    return model\n",
    "\n",
    "# Call the funciton to train the model\n",
    "# model = train_doc2vec_model(tagged_data_train)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Emeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Infer the vectors for the training data\n",
    "def infer_vectors(model, tagged_documents):\n",
    "    vectors = [model.infer_vector(doc.words) for doc in tagged_documents]\n",
    "    return np.array(vectors)\n",
    "\n",
    "# Infer the vectors for the training data\n",
    "# vectors_train = infer_vectors(model, tagged_data_train)\n",
    "# vectors_train.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Logistic Regression Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exctract features and labels\n",
    "X = vectors_train\n",
    "y = df_train['label']\n",
    "\n",
    "\n",
    "# Train Logistic Regression model\n",
    "clf = LogisticRegression(random_state=0, max_iter=1000)\n",
    "clf.fit(X, y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Making Predictions and Evaluating the Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict the labels for the test data\n",
    "tagged_data_test = create_tagged_document(df_test)\n",
    "vectors_test = []\n",
    "for i in range(len(df_test)):\n",
    "    vectors_test.append(model.infer_vector(tagged_data_test[i].words))\n",
    "    \n",
    "vectors_test = np.array(vectors_test)\n",
    "y_pred = clf.predict(vectors_test)\n",
    "\n",
    "# Calculate the accuracy\n",
    "accuracy = accuracy_score(df_test['label'], y_pred)\n",
    "f1 = f1_score(df_test['label'], y_pred)\n",
    "precision = precision_score(df_test['label'], y_pred)\n",
    "recall = recall_score(df_test['label'], y_pred)\n",
    "conf_matrix = confusion_matrix(df_test['label'], y_pred)\n",
    "\n",
    "print(f'Accuracy: {accuracy}')\n",
    "print(f'F1 Score: {f1}')\n",
    "print(f'Precision: {precision}')\n",
    "print(f'Recall: {recall}')\n",
    "print(f'Confusion Matrix:\\n{conf_matrix}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_classifier(clf, X_test, y_test):\n",
    "    y_pred = clf.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "    conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "    print(f'Accuracy: {accuracy}')\n",
    "    print(f'F1 Score: {f1}')\n",
    "    print(f'Precision: {precision}')\n",
    "    print(f'Recall: {recall}')\n",
    "    print(f'Confusion Matrix:\\n{conf_matrix}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Control Center"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Doc2Vec with vector_size=300, window=2, min_count=2, epochs=20...\n",
      "Accuracy: 0.7429969625379683\n",
      "Training Doc2Vec with vector_size=300, window=5, min_count=2, epochs=20...\n",
      "Accuracy: 0.7387782652716841\n",
      "Training Doc2Vec with vector_size=300, window=7, min_count=2, epochs=20...\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "import itertools\n",
    "import numpy as np\n",
    "\n",
    "def grid_search_doc2vec_parameters(tagged_data, df_train, df_test, y_test, param_grid):\n",
    "    best_accuracy = 0\n",
    "    best_params = {}\n",
    "    all_results = []\n",
    "\n",
    "    for vector_size, window, min_count, epochs in itertools.product(*param_grid.values()):\n",
    "        print(f\"Training Doc2Vec with vector_size={vector_size}, window={window}, min_count={min_count}, epochs={epochs}...\")\n",
    "        \n",
    "        # Train Doc2Vec model\n",
    "        model = train_doc2vec_model(tagged_data, vector_size=vector_size, window=window, min_count=min_count, epochs=epochs, workers=4)\n",
    "        \n",
    "        # Infer vectors for training and testing datasets\n",
    "        vectors_train = infer_vectors(model, tagged_data)\n",
    "        X_train = vectors_train\n",
    "        y_train = df_train['label']\n",
    "        \n",
    "        vectors_test = infer_vectors(model, create_tagged_document(df_test))\n",
    "        X_test = vectors_test\n",
    "        \n",
    "        # Train Logistic Regression model\n",
    "        clf = LogisticRegression(random_state=0, max_iter=1000)\n",
    "        clf.fit(X_train, y_train)\n",
    "        \n",
    "        # Predict and evaluate\n",
    "        y_pred = clf.predict(X_test)\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        \n",
    "        print(f\"Accuracy: {accuracy}\")\n",
    "        \n",
    "        # Keep track of the best parameters\n",
    "        if accuracy > best_accuracy:\n",
    "            best_accuracy = accuracy\n",
    "            best_params = {'vector_size': vector_size, 'window': window, 'min_count': min_count, 'epochs': epochs}\n",
    "        \n",
    "        # Store all results\n",
    "        all_results.append((accuracy, vector_size, window, min_count, epochs))\n",
    "\n",
    "    print(f\"Best Accuracy: {best_accuracy}\")\n",
    "    print(f\"Best Parameters: {best_params}\")\n",
    "    return best_params, all_results\n",
    "\n",
    "# Define your parameter grid\n",
    "param_grid = {\n",
    "    'vector_size': [768, 400, 500, 300],  # Example sizes\n",
    "    'window': [2],           # Example window sizes\n",
    "    'min_count': [2],        # Example min_count values\n",
    "    'epochs': [20]          # Example epoch counts\n",
    "}\n",
    "\n",
    "# Run the grid search\n",
    "best_params, all_results = grid_search_doc2vec_parameters(tagged_data_train, df_train, df_test, df_test['label'], param_grid)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the predicted labels to a CSV file\n",
    "df_test['predicted_label'] = y_pred\n",
    "df_test.to_csv('/Users/thebekhruz/Desktop/nlu/EvidenceExplorer/data/validate/dev_predicted.csv', index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
