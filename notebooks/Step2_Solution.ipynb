{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load pandas and numpy\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# For text preprocessing\n",
    "import spacy\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "\n",
    "# For loading Data and models\n",
    "import joblib\n",
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
    "\n",
    "\n",
    "# For evaluation we will use accuracy, f1-score, precesion, recall and confusion matrix\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, confusion_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Claim</th>\n",
       "      <th>Evidence</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>We should legalize the growing of coca leaf</td>\n",
       "      <td>Seeing the involvement of the coca growers, th...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>We should limit the use of birth control</td>\n",
       "      <td>Although FDA-approved for contraceptive use, S...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>We should prohibit flag burning</td>\n",
       "      <td>The case of Texas v. Johnson was appealed to t...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The vow of celibacy should be abandoned</td>\n",
       "      <td>Much of the encyclical is spent discussing rea...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>We should further exploit natural gas</td>\n",
       "      <td>Helium is typically produced by separating it ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         Claim  \\\n",
       "0  We should legalize the growing of coca leaf   \n",
       "1     We should limit the use of birth control   \n",
       "2              We should prohibit flag burning   \n",
       "3      The vow of celibacy should be abandoned   \n",
       "4        We should further exploit natural gas   \n",
       "\n",
       "                                            Evidence  label  \n",
       "0  Seeing the involvement of the coca growers, th...      0  \n",
       "1  Although FDA-approved for contraceptive use, S...      0  \n",
       "2  The case of Texas v. Johnson was appealed to t...      0  \n",
       "3  Much of the encyclical is spent discussing rea...      1  \n",
       "4  Helium is typically produced by separating it ...      0  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filepath_test = '/Users/thebekhruz/Desktop/nlu/EvidenceExplorer/data/validate/dev.csv'\n",
    "df_test = pd.read_csv(filepath_test)\n",
    "df_test.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Models are loaded\n"
     ]
    }
   ],
   "source": [
    "# Load the models\n",
    "try:\n",
    "    clf = joblib.load('logistic_regression_model.pkl')\n",
    "    clf_rf = joblib.load('random_forest_model.pkl')\n",
    "    clf_gb = joblib.load('gradient_boosting_model.pkl')\n",
    "    model = Doc2Vec.load('doc2vec_model')\n",
    "    print('Models are loaded')\n",
    "except:\n",
    "    print('Error: models are not loaded')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Majority Voting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implementing the majority voting function with 3 classifiers\n",
    "def majority_voting(clf1, clf2, clf3, X):\n",
    "    y_pred1 = clf1.predict(X)\n",
    "    y_pred2 = clf2.predict(X)\n",
    "    y_pred3 = clf3.predict(X)\n",
    "    y_pred = []\n",
    "    for i in range(len(y_pred1)):\n",
    "        if y_pred1[i] + y_pred2[i] + y_pred3[i] > 1:\n",
    "            y_pred.append(1)\n",
    "        else:\n",
    "            y_pred.append(0)\n",
    "    return np.array(y_pred)\n",
    "\n",
    "\n",
    "# Infer the vectors for the training data\n",
    "def infer_vectors(model, tagged_documents):\n",
    "    vectors = [model.infer_vector(doc.words) for doc in tagged_documents]\n",
    "    return np.array(vectors)\n",
    "\n",
    "def create_tagged_document(df):\n",
    "    tagged_data = []\n",
    "    for i, text in enumerate(df['Claim'] + ' ' + df['Evidence']):\n",
    "        # Process the text with the spaCy language model\n",
    "        doc = nlp(text)\n",
    "        # Tokenize and lemmatize the text, removing stopwords\n",
    "        tokens = [token.lemma_.lower() for token in doc if not token.is_stop and not token.is_punct]\n",
    "        # Create a TaggedDocument for each row in the dataframe\n",
    "        tagged_data.append(TaggedDocument(words=tokens, tags=[str(i)]))  # Tags are typically strings\n",
    "    return tagged_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "tagged_data_test = create_tagged_document(df_test)\n",
    "vectors_test = infer_vectors(model, tagged_data_test)\n",
    "y_pred = majority_voting(clf, clf_rf, clf_gb, vectors_test)\n",
    "\n",
    "# Takes around 50 seconds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.743334458319271\n",
      "Precision: 0.6681034482758621\n",
      "Recall: 0.0969355847404628\n",
      "F1 Score: 0.16930638995084654\n",
      "Confusion Matrix: \n",
      "[[4250   77]\n",
      " [1444  155]]\n"
     ]
    }
   ],
   "source": [
    "# Calculate the accuracy\n",
    "accuracy = accuracy_score(df_test['label'], y_pred)\n",
    "precision = precision_score(df_test['label'], y_pred)\n",
    "recall = recall_score(df_test['label'], y_pred)\n",
    "f1 = f1_score(df_test['label'], y_pred)\n",
    "conf_matrix = confusion_matrix(df_test['label'], y_pred)\n",
    "\n",
    "\n",
    "print(f'Accuracy: {accuracy}')\n",
    "print(f'Precision: {precision}')\n",
    "print(f'Recall: {recall}')\n",
    "print(f'F1 Score: {f1}')\n",
    "print(f'Confusion Matrix: \\n{conf_matrix}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
